name: Run Airflow DAG CI/CD

on:
  push:
    branches:
      - main
    paths:
      - 'Data_pipeline/**'
      - '.github/workflows/airflow_pipeline.yml'

  schedule:
    - cron: '0 2 * * 0'     # Weekly - Sunday at 2 AM UTC
    - cron: '0 3 1 * *'     # Monthly - 1st at 3 AM UTC

  workflow_dispatch:

jobs:
  airflow_pipeline:
    runs-on: ubuntu-latest

    env:
      AIRFLOW_USER: ${{ secrets.AIRFLOW_USER }}
      AIRFLOW_PASSWORD: ${{ secrets.AIRFLOW_PASSWORD }}
      AIRFLOW_EMAIL: ${{ secrets.AIRFLOW_EMAIL }}
      AIRFLOW_ROLE: ${{ secrets.AIRFLOW_ROLE }}

    defaults:
      run:
        working-directory: Data_pipeline

    steps:
    - name: 🧾 Checkout Repository
      uses: actions/checkout@v3

    - name: 🧪 Create .env file for Docker Compose
      run: |
        cat <<EOF > .env
        AIRFLOW_USER=${{ secrets.AIRFLOW_USER }}
        AIRFLOW_PASSWORD=${{ secrets.AIRFLOW_PASSWORD }}
        AIRFLOW_EMAIL=${{ secrets.AIRFLOW_EMAIL }}
        AIRFLOW_ROLE=${{ secrets.AIRFLOW_ROLE }}
        EOF

    - name: 🔐 Create GCP Credentials File
      run: |
        mkdir -p dags
        echo "${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}" > dags/gcp-credentials.json

    - name: 🧱 Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: 🐳 Install Docker Compose
      run: |
        sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose
        docker-compose version

    - name: 📁 Prepare logs folder
      run: |
        mkdir -p logs
        chmod -R 777 logs

    - name: 🏗️ Build Airflow Image
      run: docker-compose build

    - name: 🚀 Start Airflow Services
      run: docker-compose up -d

    - name: ⏳ Wait for Airflow to Initialize
      run: sleep 60

    - name: 🧪 Run DAG Test
      run: docker-compose exec webserver airflow dags test mlops_csv_pipeline 2025-03-03T00:00:00

    - name: 🧹 Clean Up Services
      if: always()
      run: docker-compose down -v

  deploy_to_gce:
    name: 🌐 Deploy to GCE Airflow Server
    needs: airflow_pipeline
    runs-on: ubuntu-latest

    steps:
    - name: 🔐 Authenticate with GCP
      uses: google-github-actions/auth@v1
      with:
        credentials_json: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}

    - name: 🧰 Set up gcloud CLI
      uses: google-github-actions/setup-gcloud@v1
      with:
        project_id: spheric-engine-451615-a8

    - name: 🧳 SSH into GCE and Restart Airflow
      run: |
        gcloud compute ssh airflow-vm1 --zone=us-central1-c --command='
          cd SellerCenteral-ChatBot-System/Data_pipeline &&
          git pull origin main &&
          docker-compose down -v &&
          docker-compose up -d --build
        '
